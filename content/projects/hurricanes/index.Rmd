---
title: "Hurricanes 0.1.0"
description: "Access real-time hurricane text products"
author: "Tim Trice"
tags: ["R", "Hurricanes"]
output:
    blogdown::html_page:
        toc: true
---

To go along with my [HURDAT](http://timtrice.net/projects/`HURDAT`/) package I'm releasing [Hurricanes](https://github.com/timtrice/`Hurricanes`), version 0.1.0. This library is *not* in cran and will not be submitted until release 0.2.0.

## What is `Hurricanes`

I've had a fascination with `Hurricanes` since I was a very little kid. Watching The Weather Channel's John Hope talk about Hurricane Gilbert captured me instantly. So, part of my efforts while learning R has been working with what I already know.

`Hurricanes` access and parses real-time data and returns it in dataframe format. Unlike `HURDAT`,`Hurricanes` can get the the latest data available for any cyclone in the Atlanic or northeastern Pacific ocean. 

Keep in mind `HURDAT` is a re-analysis dataset and is meant as a compliment to `Hurricanes`. `Hurricanes`, at this time, can only access it's set of data back to 1998. But, the data is much more comprehensive than `HURDAT` which goes back to 1851.

Additionally, some data in `Hurricanes` may not match up with that for `HURDAT`. For example, you may find an observation for a specific storm at a specific time has different values for latitude. This is because originally the National Hurricane Center (NHC) believed the center of the hurricane to be in one location. But, after re-analysis, determined it was somewhere else.

## Installing `Hurricanes`

With all of that said, let's examine `Hurricanes`. First, install the library using `devtools`.

```r
devtools::install_github("timtrice/Hurricanes")
```

```{r library, message = FALSE, warning = FALSE}
library(Hurricanes)

# Additional packages used for this document
library(ggplot2)
library(knitr)
library(purrr)
```

`Hurricanes` should work with any R version >= 3.2.3.

## About the Data

You can view the vignette "Getting Started" with the following command:

```r
vignette("getting-started", package = "Hurricanes")
```

I've tried to be as detailed as possible while keeping the vignette short. Here, I want to focus on what I think the best aspect of `Hurricanes` is so far. 

Hurricane text products are generally issued at the same time. But there are two products that, at this time, contain the meat of data for a particular storm: Forecast/Advisory Products and Wind Speed Probability Products (formerly Strike Probability).

Hurricanes in both the Atlantic and Pacific ocean will always have Forecast/Advisory products; the widest dataset. Functions related to this product always contain `fstadv` which is the shorthand term used by the NHC.

Wind Speed Probabilities are the longest dataset. This product is issued for every Atlantic hurricane. However, Pacific hurricanes only have this product if they are a threat to land. 

Wind Speed Probabilities were issued beginning in 2006; prior to that they were called Strike Probabilities. Those products are also available. Strike Probabilities focused on the probability of the center of a hurricane passing within 65 nautical miles of a location within a given period of time. The Wind Speed Probabilities focus on the probability of one-minute sustained winds of a certain threshold (34, 50 and 64 knots) affecting an area within a given period of time.

Wind Speed Probability functions are identified by the term `wndprb`; Strike Probabilities use the term `prblty`. 

## Getting Data

We start off by getting a list of storms that have developed in a specified year. You can pass multiple years. But, for this example, we'll stick to the current year.

```{r al2017}
(al2017 <- get_storms(year = 2017))
```

So far we've had one cyclone for each basin. Let's get the `fstadv` data for Tropical Storm Arlene.

```{r al012017}
url <- al2017 %>% filter(Name == "Tropical Storm Arlene") %>% .$Link
al012017.fstadv <- get_fstadv(link = url)
dim(al012017.fstadv)
```

You'll notice it's a pretty wide dataframe. As I would imagine many people (myself included) would want something a bit better formatted, I wrote a tidyr function to split the dataframe into four. `fstadv_split` takes the name of our original dataframe and tidy's it up. 

```{r al012017.split}
fstadv_split("al012017.fstadv")
```

Each of the datasets contains three variables: `Key`, `Adv` and `DateTime`. You can use these to join back datasets as you see fit. While you probably do not need `DateTime` for joins, I would encourage it anyway in case multiple observations share the same `Adv`. I haven't seen it. But that doesn't mean it can't happen.

Let's look at the datasets and the variables within.

## Basic Data

```{r al012017.str}
str(al012017.fstadv)
```

`Key` through `PosAcc` should all have values. I'm not aware of a situation where there wouldn't be.

`FwdDir` and `FwdSpeed` should be NA only if the system is stationary or barely moving.

`Eye` will only be available for hurricanes and only if there is an eye present. For this storm's case, there is no valid data.

The Seas variables are, in nautical miles, the distance of 12 foot seas from the center of circulation.

A couple of points:

* Do not use `Name` as any join key; notice above the `Name` values of "One". Any tropical depression that has not yet become a tropical storm is given a cardinal number as a name. Once they become tropical storms, then they are given the next name available from [the list](http://www.nhc.noaa.gov/aboutnames.shtml).

* `Adv` is a character string. Advisory products (`public`) may have intermediate advsories such as 1A, 2A, 2B. `fstadv` products are not issued in this fashion. Be cautious if you change the format.

### Track

```{r al012017.track}
ggplot(data = map_data("world"), aes(long, lat, group = group), color = "grey10") + 
    geom_path() + 
    geom_point(data = al012017.fstadv, aes(x = Lon, y = Lat), group = NA, 
               color = "red", size = 0.5) + 
    scale_x_continuous(limits = c(-100, 0), expand = c(0, 0)) + 
    scale_y_continuous(limits = c(0, 60), expand = c(0, 0)) + 
    theme_bw() + 
    labs(x = "Longitude", 
         y = "Latitude") + 
    ggtitle("Track of Tropical Storm Arlene")
```

### Wind and Gust

```{r al012017.wind}
al012017.fstadv %>% 
    gather(Var, Val, Wind, Gust) %>% 
    select(Date, Var, Val) %>% 
    ggplot(aes(x = Date, y = Val, color = Var)) + 
    geom_line() + 
    theme(legend.title = element_blank()) + 
    labs(title = "Tropical Storm Arlene Wind/Gust (kts)", 
         y = "knots")
```

### Pressure

```{r al012017.pressure}
al012017.fstadv %>% 
    ggplot(aes(x = Date, y = Pressure)) + 
    geom_line() + 
    labs(title = "Tropical Storm Arlene Pressure (mb)", 
         y = "Pressure (mb)")
```

### Seas

In this example we'll plot the radius of 12 foot seas for the last advisory, #9.

```{r al012017.seas}
quads <- c("NE", "SE", "SW", "NW")
al012017.fstadv %>% 
    select(SeasNE:SeasNW) %>% 
    slice(n()) %>% 
    rename(NE = SeasNE, SE = SeasSE, SW = SeasSW, NW = SeasNW) %>% 
    gather(Quadrant, Distance, NE:NW) %>% 
    ggplot(aes(x = factor(Quadrant, levels = quads), 
               y = Distance, 
               fill = factor(Quadrant, levels = quads))) + 
    geom_col(width = 1) + 
    coord_polar() + 
    theme_bw() + 
    labs(title = "Tropical Storm Arlene Sea Radius, Adv 9", 
         subtitle = "Distance of 12ft seas from center of circulation", 
         x = "Quadrant", 
         y = "Distance (nm)") + 
    guides(fill = guide_legend(title = "Quadrant"))
```


## Wind Radius

```{r al012017.wr}
dim(al012017.fstadv.wr)
```

For storms greater than tropical storm strength (wind >= 34 knots), a wind radius profile is included. They are issued for three values: 34, 50 and 64, and for the four quadrants: northeast, southeast, southwest and northwest. So a minimal tropical storm will have a 34 knot wind profile while a hurricane will have all three.

These values show how far from the center in nautical miles those wind values can be obtained. It's a great way to watch how the structure of a storm changes over time. Most often newborn storms have a very assymetric structure; strongest winds are generally in the northeastern quadrant while weaker winds (if any at all) can be found in the other quadrants. If the cyclone becomes better organized it's structure becomes more symmetric. 

The current storm we were working on has no wind radius values greater than 34 knots. Let's pull Hurricane Ike and look at the advisory just prior to landfall.

### Hurricane Ike Wind Radius

```{r al092008}
# Get storms for 2008
al2008 <- get_storms(year = 2008, basin = "AL")

# Load Hurricane Ike data
al092008 <- al2008 %>% 
    filter(Name == "Hurricane Ike") %>% 
    .$Link %>% 
    get_fstadv()
```

Instead of using fstadv_split, I'll show an alternative to work with the original dataframe.

```{r al092008.wr}
# Extract wind radius values
al092008.49.wr <- al092008 %>% 
    filter(Adv == "49") %>% # Remember, Adv is character string
    select(NE34:NW64)

# Rearrange to long dataframe with variables WindField, NE:NW
# i.e., 34, 50, 64
wr <- purrr::map_df(
    .x = c(34, 50, 64),
    .f = function(y) {
        select_(al092008.49.wr,
                .dots = c(paste0(quads, y))) %>%
            rename_(
                .dots = list("NE" = paste0("NE", y),
                             "SE" = paste0("SE", y),
                             "SW" = paste0("SW", y),
                             "NW" = paste0("NW", y))) %>%
            mutate_("WindField" = y)
    }) %>% 
    gather(Quadrant, Distance, NE:NW)
```

```{r al092008.wr.plot}
# Plot wind radius
ggplot(wr, aes(x = factor(Quadrant, levels = quads), 
               y = Distance, fill = factor(WindField), 
               group = factor(Quadrant, levels = quads))) + 
    geom_col(width = 1, position = position_dodge()) + 
    coord_polar() + 
    theme_bw() + 
    labs(title = "Hurricane Ike Wind Radius, Adv 49", 
         subtitle = "Distance of 34, 50, 64kt winds from center of circulation", 
         x = "Quadrant", 
         y = "Distance (nm)") + 
    guides(fill = guide_legend(title = "Max Wind (kts)"))
```

## Forecast Positions

```{r al012017.fstadv.fst}
dim(al012017.fstadv.fst)
```

Most storms will have a set of forecast positions up to five days out. These variables begin with HrN where N is 12, 24, 36, 48, 72 (and, for the more recent years, 96 and 120). 

This data contains similar data to that of the basics: latitude, longitude, wind, and and gustForward movement, eye and seas data are not forecast.

If a storm is not expected to survive after a given period of time, there will be no forecasts available.

```{r al012017.fstadv.fst.table, results = "asis", }
kable(al012017.fstadv.fst, format = "markdown")
```

What we see from the output is that the NHC had very low confidence the storm would last long. There were two forecast positions issued for advisory #1 and #4. The remaining advisories only had one forecast position. So this storm was expected to weaken within 24 hours twice (#1 and #4) and within 12 hours the remaining advisories. 

One important note regarding the `FcstDate` variable. When forecast/advisory products are issued, forecast dates and times are not exactly from issuance of the product. For example, take a look at the first [forecast/advisory](http://www.nhc.noaa.gov/archive/2017/al01/al012017.fstadv.001.shtml?) for Arlene. Note the following segment:

> REPEAT...CENTER LOCATED NEAR 31.9N  40.9W AT 19/1500Z
>
> AT 19/1200Z CENTER WAS LOCATED NEAR 31.6N  41.1W

The first line is regarding the date and time the product was issued: April 19, 15:00 UTC. The second line lists where the center was located three hours prior: April 19, 12:00 UTC. This is done in all forecast/advisory products (I've not taken the time to find out why). 

So forecast positions are based off the earlier time. Note the first forecast position in that advisory:

> FORECAST VALID 20/0000Z 32.8N  40.2W
>
> MAX WIND  30 KT...GUSTS  40 KT.

As I mentioned earlier you *probably* do not need to join dataframes using `DateTime` as a key. But I'm nearly positive at some point you will because a storm may have the same advisory number but for different dates/times. It happens. Most often these advisories will be reissued with some note somewhere the advisory was corrected. 

With that being said, I chose to stick with the date and time the product was issued as that value ties in the other products: public advisories, storm discussions, probabilities, etc. 

So, really, the `FcstDate` variable isn't 12, 24, 36, 48, 72, 96 and 120 hours from `DateTime`, but rather 12 - 3, 24 - 3, 36 - 3, etc. This is why the actual `FcstDate` variable is POSIXct instead of just having values of c(12, 24, 36, ...). 

Hope that makes sense...

## Forecast Wind Radius

For forecast wind radius:

```{r al012017.fstadv.fst.wr}
dim(al012017.fstadv.fst.wr)
```

Each forecast position (with the exception of 96 and 120 hours) will have associated wind radius if the storm is expected to be at least tropical storm strength. 

```{r al012017.fstadv.fst.wr.table, results = "asis"}
kable(al012017.fstadv.fst.wr, format = "markdown")
```

Here we see only four forecast positions where Arlene was expected to have winds of at least 34 knots, and the forecast radius of those winds. Wind radius values will exist, when appropriate, for forecast positions up to 72 hours. Forecasts at 96 and 120 hours will not have associated wind radius values. 

## Future Plans

There is a ton of data available for tropical cyclones and not just in the northwestern hemisphere. Here are some things I'm hoping to add in future releases:

* reconnaissance: there is a vast amount of this data out there waiting to be claimed. However, the products and formats of those products have changed considerably over the years. This will be a major product ([would you like to help](https://gist.github.com/timtrice/f2a4c2a020c87669178dad27e73bfce1)?) to add in though pattern-matching on this will be significantly easier than that of the advisory data. 

* gis data: I do not know how far back this data goes but it is readily avaiable for past and current storms. There is an [issue](https://github.com/timtrice/Hurricanes/issues/47) opened for this to be added; but, no milestone as of yet. 

* daily products (outlook, weather discussion): these products are in GIS format and text as well. GIS is the priorirty as I think it would be better; I'm not sure there's much value in parsing the text. But, I haven't made a decision one way or another.

* computer forecast models: this may be a little more complicated. Some of the forecast models are readily available ([SHIPS](http://rammb.cira.colostate.edu/research/tropical_cyclones/ships/index.asp), for one). Some forecast models are proprietary. Resources will need to be gathered and planned out accordingly before being added.

## Issues

I have done my best to ensure the data matches the products exactly. Unfortunately, the product formats have changed over time. And, there is no clear-set structure for some of the variables. If I could guarantee 100% accuracy this product would be in CRAN. 

Needless to say, this is beta. I will spend a great deal of time doing QA/QC on every storm, each basin to be sure. 

That being said, if you notice anything unusual, I ask you to do two things:

1. Check the [hurricane archives](http://www.nhc.noaa.gov/archive/2017/) first to verify if the error is in the package itself or in the original product. 

2. [Submit an issue](https://github.com/timtrice/Hurricanes/issues). Errors in data will be given top priority and hotfixes will be created to address any corrections that can be made. 

Optionally, 

3. [Contribute](https://gist.github.com/timtrice/f2a4c2a020c87669178dad27e73bfce1). I would love to have some help with this package as I do have a couple of other products I am working on or plan on working on. With hurricane season underway, the quicker some of the features can be implemented, the better. Any contributors will receive acknowledgements in the repo and package documentation.

Thank you for taking the time to check out `Hurricanes`. Please feel free to check out [HURDAT](http://timtrice.net/projects/hurdat/) as well. 
