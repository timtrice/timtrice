---
title: NCDC Storm Events - Importing Data
author: Tim Trice
date: "2018-10-11"
slug: ncdc-storm-events-importing-data
categories:
  - R
tags:
  - curl
  - glue
  - janitor
  - tidyverse
  - XML
header:
  caption: ''
  image: ''
params:
  script: "https://raw.githubusercontent.com/timtrice/datasets/3d6b1c39a74bda72b21e7c23550d1109a439923f/ncdc_storm_events/01_import_data.R"
---



<p>The <a href="https://www.ncdc.noaa.gov/stormevents/">NCDC Storm Events database</a> is a collection of three datasets of weather events for areas monitored by the National Weather Service. The dataset timeperiod begins in January, 1950 and ends, currently, June, 2018.</p>
<p>There are three tables included in the database (the terms “database” and “tables” are used loosely here; they’re csv.gz files on a FTP server).</p>
<ul>
<li><p>details - A 51 x <em>n</em> dataset</p></li>
<li><p>fatalities - A 11 x <em>n</em> dataset</p></li>
<li><p>locations - A 11 x <em>n</em> dataset</p></li>
</ul>
<p>A mostly complete <a href="ftp://ftp.ncdc.noaa.gov/pub/data/swdi/stormevents/csvfiles/Storm-Data-Export-Format.docx">codebook</a> is available on the <a href="ftp://ftp.ncdc.noaa.gov/pub/data/swdi/stormevents/csvfiles/">FTP server</a>. I have <a href="https://github.com/timtrice/datasets/tree/master/ncdc_storm_events">modified this document</a> to a format more readable for me.</p>
<p>Each table is split by month into a gzipped CSV file and available for download. The naming format is as such,</p>
<p>StormEvents_{TABLE}-ftp_v1.0_d{YEAR}_c{YMD}.csv.gz</p>
<p>where TABLE is one of “details”, “fatalities”, or “locations”, YEAR is the four-digit year, and “YMD” is the year, two-digit month, and two-digit date the zip file was last modified. There are no delimeters any of the fields.</p>
<p>For this phase of the project, I will be using four R libraries:</p>
<ul>
<li><p>curl - Used to retrieve FTP listings</p></li>
<li><p>glue - Insert variables within expressions</p></li>
<li><p>purrr - Map lists and dataframes</p></li>
<li><p>readr - read and write CSVs</p></li>
</ul>
<pre class="r"><code>library(curl)
library(glue)
library(purrr)
library(readr)</code></pre>
<p>I also want to go ahead and declare some variable I will use later. The first is <code>ftp</code> which is the URL to the FTP server. The second, <code>tables</code>, stores the name of each of the three tables.</p>
<p>And, last, when reading in the CSVs I found I needed to take more control rather than allowing <code>readr::read_csv</code> to guess; this would produce errors I’ll get to in a moment.</p>
<p>So, rather than typing “c” repeatedly as the col_type parameter, I just created a list ot hold the values. I use <code>glue_collapse</code> to paste the values together.</p>
<p>(I thought you could use one character that <code>read_csv</code> would repeat itself; I’m sure this was once a feature. But, unless I messed up, simply using <code>col_types = &quot;c&quot;</code> did not work.)</p>
<pre class="r"><code>#&#39; FTP URL
ftp &lt;- &quot;ftp://ftp.ncdc.noaa.gov/pub/data/swdi/stormevents/csvfiles/&quot;

#&#39; Three datasets we&#39;ll be obtaining
tables &lt;- c(&quot;details&quot;, &quot;fatalities&quot;, &quot;locations&quot;)

#&#39; Expected col_types per dataset.
table_col_types &lt;- list(
  &quot;details&quot; = glue_collapse(rep(&quot;c&quot;, 51L)),
  &quot;fatalities&quot; = glue_collapse(rep(&quot;c&quot;, 11L)),
  &quot;locations&quot; = glue_collapse(rep(&quot;c&quot;, 11L))
)</code></pre>
<pre class="r"><code>#&#39; Establish connection, get list of gz datasets
con = curl(ftp, &quot;r&quot;)
tbl = read.table(con, stringsAsFactors = TRUE, fill = TRUE)
close(con)</code></pre>
<p>Take a look at the <code>tbl</code> object.</p>
<pre class="r"><code>head(tbl)</code></pre>
<pre><code>##           V1 V2  V3   V4    V5  V6 V7   V8
## 1 drwxr-xr-x  2 ftp 1005 32768 May 14 2014
## 2 -rw-r--r--  1 ftp 1005  2020 May 14 2014
## 3 -rw-r--r--  1 ftp 1005 23834 May  6 2014
## 4 -rw-r--r--  1 ftp 1005 10597 Jan 20 2017
## 5 -rw-r--r--  1 ftp 1005 12020 Feb 24 2016
## 6 -rw-r--r--  1 ftp 1005 12634 Jun 19 2017
##                                                    V9
## 1                                              legacy
## 2                                              README
## 3                       Storm-Data-Export-Format.docx
## 4 StormEvents_details-ftp_v1.0_d1950_c20170120.csv.gz
## 5 StormEvents_details-ftp_v1.0_d1951_c20160223.csv.gz
## 6 StormEvents_details-ftp_v1.0_d1952_c20170619.csv.gz</code></pre>
<p>This is basically a representation of the FTP site in a dataframe format. All that I am concerned with is <code>tbl$V9</code> which are the file names. I can glue this to <code>ftp</code> within a recursive function using pattern matching to extract only the files I want.</p>
<p>The pattern matching portion is easy; every file name starts with “StormEvents_” followed by one of “details”, “fatalities”, or “locations”.</p>
<p>I’ll use <code>purrr::map</code> to build a list of length three for each table, then assign each element of the list the name of it’s respective table.</p>
<pre class="r"><code>#&#39; Split out the datasets into their own lists. Will end up with a list of
#&#39; length 3 for each table containing all related dataset URLs
by_table &lt;-
  map(
    .x = glue(&quot;^StormEvents_{tables}&quot;),
    .f = grep,
    x = tbl$V9,
    value = TRUE
  ) %&gt;%
  set_names(nm = tables)</code></pre>
<pre class="r"><code>str(by_table)</code></pre>
<pre><code>## List of 3
##  $ details   : chr [1:69] &quot;StormEvents_details-ftp_v1.0_d1950_c20170120.csv.gz&quot; &quot;StormEvents_details-ftp_v1.0_d1951_c20160223.csv.gz&quot; &quot;StormEvents_details-ftp_v1.0_d1952_c20170619.csv.gz&quot; &quot;StormEvents_details-ftp_v1.0_d1953_c20160223.csv.gz&quot; ...
##  $ fatalities: chr [1:69] &quot;StormEvents_fatalities-ftp_v1.0_d1950_c20170120.csv.gz&quot; &quot;StormEvents_fatalities-ftp_v1.0_d1951_c20160223.csv.gz&quot; &quot;StormEvents_fatalities-ftp_v1.0_d1952_c20170619.csv.gz&quot; &quot;StormEvents_fatalities-ftp_v1.0_d1953_c20160223.csv.gz&quot; ...
##  $ locations : chr [1:69] &quot;StormEvents_locations-ftp_v1.0_d1950_c20170120.csv.gz&quot; &quot;StormEvents_locations-ftp_v1.0_d1951_c20160223.csv.gz&quot; &quot;StormEvents_locations-ftp_v1.0_d1952_c20170619.csv.gz&quot; &quot;StormEvents_locations-ftp_v1.0_d1953_c20160223.csv.gz&quot; ...</code></pre>
<p>I now have a nice, clean listing of all my files for each table.</p>
<p>It’s time to read in the CSVs. Again, I fall back to <code>purrr</code> but I want to use <code>map_df</code> this time; I want one dataframe for each <code>table</code>. I’ll describe my parameters.</p>
<ul>
<li><p><code>.x</code> - I use <code>glue</code> again to effectively take all of the values in <code>by_table$details</code> and append the <code>ftp</code> variable.</p></li>
<li><p><code>.f</code> - As I’ll be reading in CSV files, I use <code>read_csv</code> from the <code>readr</code> package.</p></li>
<li><p><code>col_types</code> - Originally I left this parameter to it’s default. However, this would prove to be an issue. <code>read_csv</code> guesses a column type for each column in a CSV; this is controlled by the <code>guess_max</code> parameter which defaults to the smaller value of 1000 or the <code>n_max</code> parameter. Some values would be guessed to be numeric. But, on importing the datasets it might find a character that would generate a warning. To deal with this during cleanup, I decided to make them all characters.</p></li>
</ul>
<p>I then save the datasets to a <a href="https://git-lfs.github.com/">Git LFS</a> repo.</p>
<pre class="r"><code>#&#39; Get the details dataset (this can take a while)
details &lt;-
  map_df(
    .x = glue(&quot;{ftp}{by_table$details}&quot;),
    .f = read_csv,
    #&#39; Make character to avoid reading errors or warnings
    col_types = table_col_types$details
  )

write_csv(details, path = &quot;./ncdc_storm_events/details.csv&quot;)</code></pre>
<pre class="r"><code>#&#39; ...fatalities (can take a while, too)...
fatalities &lt;-
  map_df(
    .x = glue(&quot;{ftp}{by_table$fatalities}&quot;),
    .f = read_csv,
    #&#39; Make character to avoid reading errors or warnings
    col_types = table_col_types$fatalities
  )

write_csv(fatalities, path = &quot;./ncdc_storm_events/fatalities.csv&quot;)</code></pre>
<pre class="r"><code>#&#39; ...and locations (a bit faster.
locations &lt;-
  map_df(
    .x = glue(&quot;{ftp}{by_table$locations}&quot;),
    .f = read_csv,
    #&#39; Make character to avoid reading errors or warnings
    col_types = table_col_types$locations
  )

write_csv(locations, path = &quot;./ncdc_storm_events/locations.csv&quot;)</code></pre>
<p>Next, I’ll start performing some cleanup. And, whoo boy, is there some cleaning to do.</p>
<p><a href="https://raw.githubusercontent.com/timtrice/datasets/3d6b1c39a74bda72b21e7c23550d1109a439923f/ncdc_storm_events/01_import_data.R">Script</a></p>
<div id="session-info" class="section level2">
<h2>Session Info</h2>
<pre class="r"><code>pander::pander(sessionInfo())</code></pre>
<p><strong>R version 3.4.4 (2018-03-15)</strong></p>
<p><strong>Platform:</strong> x86_64-pc-linux-gnu (64-bit)</p>
<p><strong>locale:</strong>
<em>LC_CTYPE=C.UTF-8</em>, <em>LC_NUMERIC=C</em>, <em>LC_TIME=C.UTF-8</em>, <em>LC_COLLATE=C.UTF-8</em>, <em>LC_MONETARY=C.UTF-8</em>, <em>LC_MESSAGES=C.UTF-8</em>, <em>LC_PAPER=C.UTF-8</em>, <em>LC_NAME=C</em>, <em>LC_ADDRESS=C</em>, <em>LC_TELEPHONE=C</em>, <em>LC_MEASUREMENT=C.UTF-8</em> and <em>LC_IDENTIFICATION=C</em></p>
<p><strong>attached base packages:</strong>
<em>methods</em>, <em>stats</em>, <em>graphics</em>, <em>grDevices</em>, <em>utils</em>, <em>datasets</em> and <em>base</em></p>
<p><strong>other attached packages:</strong>
<em>readr(v.1.1.1)</em>, <em>purrr(v.0.2.5)</em>, <em>glue(v.1.3.0)</em> and <em>curl(v.3.2)</em></p>
<p><strong>loaded via a namespace (and not attached):</strong>
<em>Rcpp(v.0.12.17)</em>, <em>knitr(v.1.20)</em>, <em>magrittr(v.1.5)</em>, <em>hms(v.0.4.2)</em>, <em>R6(v.2.2.2)</em>, <em>rlang(v.0.2.1)</em>, <em>stringr(v.1.3.1)</em>, <em>tools(v.3.4.4)</em>, <em>xfun(v.0.1)</em>, <em>htmltools(v.0.3.6)</em>, <em>yaml(v.2.1.19)</em>, <em>rprojroot(v.1.3-2)</em>, <em>digest(v.0.6.15)</em>, <em>tibble(v.1.4.2)</em>, <em>bookdown(v.0.7)</em>, <em>evaluate(v.0.10.1)</em>, <em>rmarkdown(v.1.9)</em>, <em>blogdown(v.0.6)</em>, <em>stringi(v.1.2.2)</em>, <em>compiler(v.3.4.4)</em>, <em>pander(v.0.6.2)</em>, <em>pillar(v.1.2.3)</em>, <em>backports(v.1.1.2)</em> and <em>pkgconfig(v.2.0.1)</em></p>
</div>
