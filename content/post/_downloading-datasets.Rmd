---
layout: post
title: Downloading Datasets in NCDC Storm Events
tags:
- NCDC_Storm_Events
excerpt: Using the NCDC Storm Events library (available only in my Github repository) to access the datasets.
---

<!-- START doctoc -->
<!-- END doctoc -->

```{r, echo = FALSE, message = FALSE}
knitr::opts_chunk$set(fig.width = 10)
```

```{r}
library(NCDCStormEvents)
```

## Analysis of Files

We access `get_listings` so we have all of the datasets available by `Year`, `Type` and `Size`:

```{r}
ds_list <- get_listings()
```

Next, we need to decide what datasets we want to evaluate. First, let's see exactly what we're dealing with:

```{r, fig.height = 5, fig.cap = "Details, Fatalities and Locations by Year, Size"}
library(ggplot2)

base_plot <- list( 
    scale_x_discrete(breaks = c(seq(1951, 2015, by = 10))), 
    geom_bar(stat = "identity", position = position_dodge()), 
    facet_grid(Type ~ ., scales = "free_y"), 
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, size = 10), 
          legend.position = "none"), 
    scale_fill_discrete(name = "Type"), 
    xlab("Year"))

ggplot(ds_list, aes(x = factor(Year), y = Size, fill = factor(Type))) + 
    scale_y_continuous(label = function(x){x * 10^-6}) + 
    ggtitle("Details, Fatalities and Locations by Year, Size") + 
    ylab("Size (MB)") + 
    base_plot
```

**Note the y-axis has been set to free scales for each `Type`.**

Obviously, as we get intot he more recent years our datasets get largers; particularly `details`. This is why you should be careful requesting multiple years. Our fatalities isn't quite as large (a good thing) topping out around a very small 15kb (and that's an outlier). 

We can also see we don't have `locations` until 1996. 

It might seem like we have no `details` datasets prior to 1957. However, this is not correct; it's merely the scale of the later years dominating our graph. 

Let's look at the data between 1951 and 1995:

```{r, fig.height = 5, fig.cap = "Details, Fatalities and Locations by Year (1951-1995), Size"}
tmp <- ds_list[Year <= 1995,]

ggplot(tmp, aes(x = factor(Year), y = Size, fill = factor(Type))) + 
    scale_y_continuous(label = function(x){x * 10^-3}) + 
    ggtitle("Details, Fatalities and Locations by Year (1951-1995), Size") + 
    ylab("Size (KB)") + 
    base_plot
```

Notice I've dropped the scale from MB to KB now.

Now we can see a bit clearly our early `details` datasets and yes, they are there. 

But, now we have all `locations` datasets the same size? Seems odd. These are, in fact, empty. These files contain only the header row. So, there really is no sense pulling them unless you want a bunch of empty data tables. 

## Requesting Summary Data

If I just want to see the `details` for 1951, I first want to see the total file size of the data I'm requesting:

```{r}
year <- 1951
type <- "details"

x <- ds_list[Year == year & Type == type, Size]
```

Just pulling this one dataset is `r formatC(x, format = "d", big.mark = ",")`b or approximately `r formatC(x*10^-3, format = "d", big.mark = ",")`kb. This is for a *gzip* file (all of the datasets are gzip). So the file size will be a bit larger; in this case though, it shouldn't be much.

So, this isn't bad at all. But, what if we wanted to look at datasets between 2005 and 2010?

```{r}
year <- 2005:2010
type <- "details"

x <- ds_list[Year %in% year & Type == type, sum(Size)]
```

Here, we're dealing with `r formatC(x, format = "d", big.mark = ",")`b or `r formatC(x*10^-6, format = "d", big.mark = ",")`mb of data. So, we're sending a request to download five datasets at an average of `r formatC((x*10^-6)/5, format = "d", big.mark = ",")`mb per file. 

If we wanted *all* of the datasets we'd be looking at a total of `r sum(ds_list$Size)`b or `r format(sum(ds_list$Size) * 10^-6, format = "d", big.mark = ",")`mb. 

And, again, these are for gzip files so the extracted CSV files will be larger. Keep this in mind.

## Requesting Datasets

The purpose of `get_listings` is to show you what is available. To get the data we have to use - and it took forever to come up with this name - `get_data`.

`get_data` takes `year` as a required parameter. `type` is optional but will return the three main types of datasets, `details`, `fatalities` and `locations`. `get_data` merges the requested types on `EVENT_ID` provided each dataset has a minimum of one row of data (remember `locations` may have empty datasets).

Here is a basic look at the `details` dataset for 1951:

```{r}
DT <- get_data(1951, type = "details")
```

What does `DT` contain?

```{r}
dim(DT)
str(DT)
```

There is a lot of data in here. And you may notice a lot of it is redundant. We'll tackle that in the [Cleaning Datasets](/cleaning-datasets.html) vignette. 

Looking at this, it's easy to see why they grow so exponentially in the later years!

You don't have to provide `type`; by default it will return the three types of datasets.

```{r}
DT <- get_data(1951)
```

You see we got an error message stating *No locations returned* and, of course, we expected this. At this time that message should only generate for empty `locations` datasets as there are no empty `details` or `fatalities` datasets. But that may change with new datasets and the message will be similar.

